{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./data/ratings_test.txt', <http.client.HTTPMessage at 0x1d40ddd2b80>)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", \n",
    "                           filename=\"./data/ratings_train.txt\")\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", \n",
    "                           filename=\"./data/ratings_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.read_table('./data/ratings_train.txt')\n",
    "test_data=pd.read_table('./data/ratings_test.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id          0\n",
      "document    5\n",
      "label       0\n",
      "dtype: int64\n",
      "id          0\n",
      "document    3\n",
      "label       0\n",
      "dtype: int64\n",
      "150000 50000\n"
     ]
    }
   ],
   "source": [
    "print(train_data.isnull().sum())\n",
    "print(test_data.isnull().sum())\n",
    "print(len(train_data),len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'저재ㅓ재버장배업ㅈㄹㅓㄹ'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.sub(r'[^ㄱ-ㅎㅏ-ㅣ가-힣]','',sample_hangul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149186 49726\n",
      "0                                         아 더빙 진짜 짜증나네요 목소리\n",
      "1                                흠포스터보고 초딩영화줄오버연기조차 가볍지 않구나\n",
      "2                                         너무재밓었다그래서보는것을추천한다\n",
      "3                                 교도소 이야기구먼 솔직히 재미는 없다평점 조정\n",
      "4         사이몬페그의 익살스런 연기가 돋보였던 영화스파이더맨에서 늙어보이기만 했던 커스틴 던...\n",
      "                                ...                        \n",
      "149995                                      인간이 문제지 소는 뭔죄인가\n",
      "149996                                           평점이 너무 낮아서\n",
      "149997                        이게 뭐요 한국인은 거들먹거리고 필리핀 혼혈은 착하다\n",
      "149998                           청춘 영화의 최고봉방황과 우울했던 날들의 자화상\n",
      "149999                             한국 영화 최초로 수간하는 내용이 담긴 영화\n",
      "Name: document, Length: 149186, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#한글을 제외한 문자를 ''로 변경\n",
    "train_data['document']=train_data['document'].str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣 ' ']','',regex=True)\n",
    "test_data['document']=test_data['document'].str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣 ' ']','',regex=True)\n",
    "\n",
    "#''를 np.nan으로 변경 ->nan 을 제거\n",
    "train_data['document'].replace('',np.nan,inplace=True)\n",
    "train_data.dropna(inplace=True)\n",
    "test_data['document'].replace('',np.nan,inplace=True)\n",
    "test_data.dropna(inplace=True)\n",
    "\n",
    "print(len(train_data),len(test_data))\n",
    "print(train_data['document'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 긍정 리뷰는 1, 부정 리뷰는 0으로 클래스를 지정합니다.\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Embedding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "x_train = train_data['document'].to_list()\n",
    "y_train= train_data['label'].to_numpy()\n",
    "\n",
    "\n",
    "token=Tokenizer()\n",
    "token.fit_on_texts(x_train)\n",
    "x=token.texts_to_sequences(x_train)\n",
    "padded_x=pad_sequences(x, maxlen=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'token' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m word_size\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(token\u001b[39m.\u001b[39mword_index)\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m      2\u001b[0m word_size\n",
      "\u001b[1;31mNameError\u001b[0m: name 'token' is not defined"
     ]
    }
   ],
   "source": [
    "word_size=len(token.word_index)+1\n",
    "word_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_15 (Embedding)    (None, 10, 8)             2396832   \n",
      "                                                                 \n",
      " flatten_15 (Flatten)        (None, 80)                0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,396,913\n",
      "Trainable params: 2,396,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model=Sequential()\n",
    "model.add(Embedding(word_size,8,input_length=10))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "292/292 [==============================] - 9s 28ms/step - loss: 0.6352 - accuracy: 0.6977\n",
      "Epoch 2/20\n",
      "292/292 [==============================] - 8s 27ms/step - loss: 0.4423 - accuracy: 0.8481\n",
      "Epoch 3/20\n",
      "292/292 [==============================] - 8s 27ms/step - loss: 0.3143 - accuracy: 0.9103\n",
      "Epoch 4/20\n",
      "292/292 [==============================] - 8s 28ms/step - loss: 0.2282 - accuracy: 0.9423\n",
      "Epoch 5/20\n",
      "292/292 [==============================] - 8s 27ms/step - loss: 0.1679 - accuracy: 0.9601\n",
      "Epoch 6/20\n",
      "292/292 [==============================] - 8s 28ms/step - loss: 0.1264 - accuracy: 0.9716\n",
      "Epoch 7/20\n",
      "292/292 [==============================] - 8s 29ms/step - loss: 0.0977 - accuracy: 0.9778\n",
      "Epoch 8/20\n",
      "292/292 [==============================] - 9s 31ms/step - loss: 0.0776 - accuracy: 0.9829\n",
      "Epoch 9/20\n",
      "292/292 [==============================] - 9s 30ms/step - loss: 0.0633 - accuracy: 0.9861\n",
      "Epoch 10/20\n",
      "292/292 [==============================] - 8s 28ms/step - loss: 0.0529 - accuracy: 0.9882\n",
      "Epoch 11/20\n",
      "292/292 [==============================] - 8s 28ms/step - loss: 0.0452 - accuracy: 0.9896\n",
      "Epoch 12/20\n",
      "292/292 [==============================] - 8s 28ms/step - loss: 0.0392 - accuracy: 0.9907\n",
      "Epoch 13/20\n",
      "292/292 [==============================] - 8s 28ms/step - loss: 0.0347 - accuracy: 0.9916\n",
      "Epoch 14/20\n",
      "292/292 [==============================] - 8s 28ms/step - loss: 0.0310 - accuracy: 0.9923\n",
      "Epoch 15/20\n",
      "292/292 [==============================] - 8s 28ms/step - loss: 0.0281 - accuracy: 0.9927\n",
      "Epoch 16/20\n",
      "292/292 [==============================] - 8s 28ms/step - loss: 0.0258 - accuracy: 0.9932\n",
      "Epoch 17/20\n",
      "292/292 [==============================] - 8s 27ms/step - loss: 0.0238 - accuracy: 0.9934\n",
      "Epoch 18/20\n",
      "292/292 [==============================] - 8s 27ms/step - loss: 0.0222 - accuracy: 0.9936\n",
      "Epoch 19/20\n",
      "292/292 [==============================] - 8s 27ms/step - loss: 0.0208 - accuracy: 0.9940\n",
      "Epoch 20/20\n",
      "292/292 [==============================] - 8s 27ms/step - loss: 0.0196 - accuracy: 0.9941\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d40fa7c730>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(padded_x, y_train, epochs=20,batch_size=512)\n",
    "\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test_data['document'].to_list()\n",
    "y_test= test_data['label'].to_numpy()\n",
    "\n",
    "\n",
    "token=Tokenizer()\n",
    "token.fit_on_texts(x_test)\n",
    "y=token.texts_to_sequences(x_test)\n",
    "padded_y=pad_sequences(y, maxlen=10)\n",
    "word_size=len(token.word_index)+1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1554/1554 [==============================] - 2s 1ms/step - loss: 2.0218 - accuracy: 0.5041\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.504142701625824"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(padded_y, y_test)[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
