{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 422155448944656492\n",
       " xla_global_id: -1,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 3715713024\n",
       " locality {\n",
       "   bus_id: 1\n",
       " }\n",
       " incarnation: 817332697773085365\n",
       " physical_device_desc: \"device: 0, name: DML, pci bus id: <undefined>\"\n",
       " xla_global_id: -1]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_pretrained = keras.applications.vgg16.VGG16(\n",
    "    weights = 'imagenet',\n",
    "    include_top = True,\n",
    "    input_shape= (224,224,3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 1000)              4097000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(vgg16_pretrained.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pydot\n",
    "#pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=RGB size=224x224 at 0x2E922FA4088>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "img_path='./images/airplane_1.jpg'\n",
    "img = keras.preprocessing.image.load_img(img_path,target_size=(224,224))\n",
    "x= keras.preprocessing.image.img_to_array(img)\n",
    "x= np.expand_dims(x,axis=0) # 디멘션을 하나 더넣어줌으로 사진여러장을 한번에 학습가능\n",
    "x= keras.applications.vgg16.preprocess_input(x)\n",
    "print(img)\n",
    "print(type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAABGUElEQVR4nO3dd5xU1fnH8c/sbGVpSwdBEOkgiFJERDEQ7CZGYywQMdYY5aeJDRONmhhN0Rij0STWNHs3SlQUC02qIEVBioiw1N0Fts+c3x/PnTuzu7O7s41d2O/79bovhil37s7O3uee85zznIBzziEiIgIkNfYBiIhI06GgICIiPgUFERHxKSiIiIhPQUFERHwKCiIi4lNQEBERn4KCiIj4FBRERMSnoCAiIj4FBRER8SkoiIiIT0FBRER8CgoiIuJTUBAREZ+CgoiI+BQURETEp6AgIiI+BQUREfEpKIiIiE9BQUREfAoKIiLiU1AQERGfgoKIiPgUFERExKegICIiPgUFERHxKSiIiIhPQUFERHwKCiIi4lNQEBERn4KCiIj4FBRERMSnoCAiIj4FBRER8SkoiIiIT0FBRER8CgoiIuJTUBAREZ+CgoiI+BQURETEp6AgIiI+BQUREfEpKIiIiE9BQUREfAoKIiLiU1AQERGfgoKIiPgUFERExKegICIiPgUFERHxKSiIiIhPQUFERHwKCiIi4lNQEBERn4KCiIj4FBRERMSnoCAiIj4FBRER8SkoiIiIT0FBRER8CgoiIuJTUBAREZ+CgoiI+BQURETEp6AgIiI+BQUREfEpKIiIiE9BQUREfAoKIiLiU1AQERGfgoKIiPgUFERExKegICIiPgUFERHxKSiIiIhPQUFERHwKCiIi4lNQEBERn4KCiIj4FBRERMSnoCAiIj4FBRER8SkoiIiIT0FBRER8CgoiIuJTUBAREZ+CgoiI+BQURETEp6AgIiI+BQUREfEpKIiIiE9BQUREfAoKIiLiU1AQERGfgoKIiPgUFERExKegICIiPgUFERHxKSiIiIhPQUFERHwKCiIi4lNQEBERn4KCiIj4FBRERMSnoCAiIj4FBRER8SkoiIiIT0FBRER8CgoiIuJTUBAREZ+CgoiI+BQURETEp6AgIiI+BQUREfEpKIiIiC+5sQ9ARCRxRUCOdzsJaAcEG+1oDkZqKYjIAWQWMNzbJgA7GvVoDkZqKYhIE7cAitfCDKDtQhi3BeYBW/bBKS9CRlac1/QGRu/fwzxIBJxzrrEPQkTEuDg3r4KcR6xxMAx4BbgI+B+wBOgWbz+XAH/3bgca5EgPVmopiEgT8g/gdbu5DPg1cOliGFXT/cwEvg/cAhxVf4fXDCgoiEgTUARsA2ZD+EXIBlYALwLfIhoUCoBNwD4gBHwDpAHty+9vg7edCXQs91hHLDmdDbQE2njv7YDONPeWhYKCiDQBS7ETeJ6d+M8CVlKmNwmI5pn3AiXAJOAc4G+V7fdqICXm/0HgZSyKTAQuB6YDPwRKgbeA1Dr+LAc2BQUR2c92AK8BYbvafw3YudbuHx2Gvtj5OgtLLs/GLt5PA74A3gVOAA7Bzu+fAo9ig5EOK/9ee2JuDwbGAPOxqLINmAs8DqzBhreKEs0i0oDiJY4XA8dCoBgKsfP0Uu+h3wM/826/C5wMhIG2WFL5U+C7wFNYK+EoYIv3/BeAs6s6lmnAvVjE+SDO4yOwCNS8WwoKCiLSgLZjV+IboHQD3AiU5MF9cyHFWUthLjbE9CagHzAQ+BOQASwAHgTmUDYoDAX6AOcDmd5bDQe6VHUsPb2dfwLsirk/iEWjUViEat7Tt9R9JCL1LAcLBhlYMvdj4HNgjSWJS4i2GoLAcd5T+wJbgY1YPmEI1lJ4DQsKYAGgD5APbAaOBzolelwbvS1WFpZcPhE4MtEdHdTUUhCRevY34AbgGKwr5h2gBFzYTuYALSg7yKcUe+znWMsgE8sRvAz8BHgGaykcgiWi8V6fSR0v7K8Dbvd2pHIZoJaCiNSbXOBpLBmQB6zFTjHFsNBZN9E52Ln3CWAk0UnH27Dhp1nAj7Eg8DnwALA85i1SKDuYqMYC2NCm7t7/TwRa12WHBx21FESkDhyWCQbcOgiPwAICdgUfaQ38FvgFNqQ0Fesy+jlwm/f4x8B44B7gSizn+znRVkBbYBHQqy7HGsAiUmT4ksSjloKI1MEM7IwPbCmAy/bZxLIANtAndjJxCLjGe6wkgV0fjeV/A9iZqsokciLOwkYgDavrjg5qCgoiUkObsK4iYPci2OwN79yG5Zc3YfnlpVjPTG+gAzAIKCaaE9iGJZTLzy1IwpLJXbEL+joPBkr1DmIEaiFUT91HIlJDU7AEAPDPEFxRbLd7Ae9haYWfYuUnBgMfYXmASOtgCVa6IoxVmZiFzTEbj3Uf/QybvxDw9lHnqhO9seFLWTT3OQiJUEtBRKqRj8012Ov9/1PYU2B35WI9MmATgttig45uxJLFXwN/AMZhOV2w4HEDFgwWYmmJ7t5rRmFBIKOuxzwUOMW73R6rb6SAkAi1FEQkjjAQsjxAeAfW9fJN9OFvsJP/KcBfvfsieVyHtQpOx078YC2HX3uPR7qD7sByBrOpp27+INFmxY9iDiyGcxAO2e2kIASad/G7eBQURCSOj4Hr4VfAf0uwcaEx2eE22NX+SuA/3n2HYOUnZmBJ5quwCWlglazfBB4BjvDu24SVqBhMdFZynfyGaHOkE9ZtVE44DPf+BPbkwi8eh9T0+njjg4q6j0QkqrQUVq2C9DXQpxTCG6Bwp538W2Ln2XVY984wrGepFJuSsN277TUyGIDNSl6FXcCXUrbqaQ9vq7VkLHtdhGW204me0qrITofCEC6tWIFVALUURCRWbi6MHg0D+8NLz0Hocsj+h/X1Hwv8G7gQy9suxfIIpcD3gNXYXIJWWFBIxuYaHItVqP6Vd1+9lRbqiBVH+hKb5bYYq5MB1n30SMWXOAehUrsdTFb3URxqKYg0S//DuojALv+nwhsBmJ8GF1wN/ToAqZCcFM3PJmGjiJKw0UL3AGOx4f8BrMbcb7B6RKd7r+mAFbobST3leQcAF3i3M7Go9JV3UCGsCXOVd2BxBAKQXKcp0Qc9BQWRZiWMTRaYAe5+uxn4FqRcBDMC8K90WHQ19ApBUREEQpZKSMPOu0Xev8XAfViX0SnebnOxC/ZiokGhI3BzfR17KtYf9QssCjnvgIq9A3DYxIj/w6KR1IaCgkizsgzrWvna5gJcgJ0/yw/UmT0bpk2D7l9ZAvmf2PKYo7ECdT8CzgXewEYhrQe6Ac9iFarrXStv5wNi7tsF/ABbdnM7luBIx4Y1jfcek5pSUBBpFsLAp5A3D5Z9Cr3CNpfrcyAvB/gIDu8LI7vBZ8DqPPj0UzvX5mIzjL/GYsoWLFCMxkpagCWdu3n/tqzrsSZhiyPETlZohZW27ur9/3NvWwrs9O4b4B1Ya2rWVxXGfjCH/QDNez0FJZpFmoUiYCzMWQInhuEurBrpSOw8+04QeAByrrKT/bo3IHyGvbQjNgv5Y+A87Jx5CLZWTWwvTYCyRfBqLRNbMrN/FTufijVfwjHPeZbo0muR5yeiBCt/EcKmXzfvSW5qKYgcdELAQ1i3Sux9X1FmXeSN2EjOrt7jSWE7H98M5A4C7oVnnoH1C8ru/kKsymlrGuAM0gU4FFtwIXbn+VgSI7Ji2idEA8JwYLL3b23WREjCKvWFa/n6g4uCgshBIYydOB121v8PdrVdThLWvTMPuygGG1K6B8gogrS9cEkL7MR8GSxfHA0KKd5rv4sNQa03GURPxt2Aw7Gr9VKi1fNygL9jgQ0s8x3ppxqGTZmujWKsFXUuCgimeXeeiRw01mOX7yOwSQWfxn/aMOwie0rMfQu8lzz3OyxBuxmLGCOA16PP+zZWq+jb9XncqVgAW+htk2Mem4/1b43AZirHlNngzpjX3FWH938Sy5Qvr+Z5zUczaymsB9ZgfwFtG/dQRGotH7vUj12UYBM2e6yo6pdmAP2w4f2x9/UENm+DmXthzHvQYiPwhY0A3YddmLeibDd/jfTy3jjWWix7XYQtzLMbC0hbgA+wAnyxQ5kOj7l9VA0OJh9b9s2bxbwQayAcAwS3ee+RlviPcpBrZonm3wO3YF+4Yxv5WERqaz12UsyNua+Gf8Y3YNVLwS7C3wauxWYsLwpAbxfdrcPytnVKIN+AzXaLdTt2lT+eaJI3kicIABOBtyp545oc0BqstbHH3mYiNqrqE6DFjdiMuzr/gAeNg7yl4ID7sSsogM5YAq431jf5W+Bk4IzGODiRGpiLdXWAJQAi+YNaOhurO3QP0YE652GrnXWI2W+dz5VdgelYN1BVvdWR6HM20f6p7tR+ONPH2OgksFZIAbzn4DlsYl2PrpA6Hes1UC96rIMwKISwL0HkS/YK8KH32PVYERawOimPYsmq47C28UH4ccgBbC/WzwE2JvRv9bfrY7BqpU8Tzdce5231piXWNXMJNpooIpLZLvT+H5mPkIW1Gq5IYN/7qLqrbBH+5xU5JXyaBi+0gFeBsT2wANQ2gfdqXg7Cs+Bm4DT8xcPZVs3z/wq8DLyEdaCKNBU3E0307qvqibWTgS2gFrsMQb0JYCflE7BZxrFWYcOXtmOnoJ8BA7GTfFaC+78Vf/W3uPZGb27CTgknnw+LbrcOA9Zj/WY/woozScRBGBRKKbOGbBlrsAAA9qWIFGwpIHpFJtLYNmMd3kuJDsFsAEnYCNB60wI70aZgQWFw2TcIh+GjjyC8Fo4fCsGw99xe2PyE8rZh5ViHYbPl3se6zYBFS+Ar77PpjvVO4T38PmX/nPd4hzIwH3pmYzOfA9gM6Xr9AA4KB2GieR0Vk3DVScX6bI9qkCMSqZnnsXHzB5reWLdNm5j7YpogJSVw/PFQXAxz5kBaavzn+d4BTsLygOdhf58b7KEfEk0ZnE90oZ9N2By2ndG90Mc7rFaHQ+BILME9uJr3br4OwpZCJ6xL6C1sGahElGLN0dHAz9EkFtn//o6NioMGbR3Umyxsfc3WWO7uPqJdtgGsFf5b2LwCbsNyx+cmwS8vhHBvSE4m8ZPxk9i6ntttzMizlJ2GMZfo9IZ8rGXgHdUfgE+zgcvhpNOOZMqUaVjTQoGgMgdhUGiJVUfcSeJBIYytFbgbG7Iq0tDC2HfUWy+Y97Gsb1OWRjQx2wX7O2uPnX7fxnIFO7AEsgPmwt5P4D2shygpGU6ehg0PrUoYK2ex2/v/JxD+xD6uz7E0y9cxT99A2YoeABkZ0Lo17+3ezYw9xfAstO98CFOmHF+zH7kZOgiDgsiBYB82FHqj9/+adHc2lklEa2wHKZsUfgBbAe0ULMkbAB6Bw/9qV/KZePfFzpqrTAFWS2Ml/rDbPViy+Evvdmk1uzjrLPjDH2DyZHjvvQTeUyIUFMrYgV2tHY2t/SpSn3KwEs27sZE366l+dFxjOwbLFYB1r3YhftfLp9hAjmOxM3YAOBySu8bPIQP2WcQrL1GE5Qa9lkIk576eaD28eMaNgx7eos/jx0OXLpDavCue1oaCQhlrsAzW77AhcqC+R6mdeOM3NmFX1Euwk96B4HLgYu+2K/dv7N/GH7Duo0UkPvb/BWzhZqqeh/cEcZdbrmDaNDjnnOj/nSNQfg3myLgarc1cqYNw9FHEOuyP7w5qXuxqCDaz57fYtE+RmvoCG7QQirkvDztx5tIg8w7q1dFYfu1oovWHVmM1t9dgZ/F7sZFGXv6APcC3sGGmiViJ/W3eDBs22LSGbKKphIilWCsh1jXXWGsg1ujRcMgh/n+dc8yZM4fspUvhhhs4vFs3hh15JNx+OwzRnKTKHMQthd5YduvhWrz2M6zz8hJsuGon1GKQxDjszLYKm01fXed3YwpgfTuR08BuLFh1wS6KzvKeEwK2YlneedgFV6S0dWQ/taglltMN8lKAFrbrd7CBV/F61AIB6NoVgt7IwBNOgO9VXb87EAgwduxYSjp1Yuv06bTM/hIWrYe9V9f8WJuRgzgo1FUBNg1+PDbbWUFBElGCrUKzkKYdEMCmNL9AtNroTVhxoDeAvjHP243NFyjFcm2/xWoGxc5HqIVHHoHf/w7Is13nU7ZhFat1a/jvf6M5g5aJr/m5CZtSd8EFcPfdWEUbqZSCQpVysSbz37GiMIOrfro0M2HsBLo15r4Q1srMi/uKxtcJG/WUhF3t98KGlYKVowhhLeVNWIsH7Ix9AjaE6DCshHWi5Sgq2rFjB6+++irDZ8/mqF3l+4piHIINZgqMhRYjoHt3aN++8udXIoSFtfz0wdBuLNF1niWeZhAU6nqF/zlwJfBnoiOS1GpovmJTcCGsHPvHjXQstdEHy9pW9qdfjNXP3oN1FTmiizQfUslryov9jKJ/K5H05YYNG7jqqqv4eXFx1TUEBmEjYJMmY3+DtWd55QnAn+q0n+bgIA8KAaxW+rnYGqzVLEBSpb9gE4weRFcazdlm7LtUgJ38VjTu4STkQqJTfttSdanoEDaC6GhsQidYi6ImV+ivY7m8u7H6Qt6eQyFuuOEG5s+fT0lJSfyXXgqcnQ48AO17eDGlbsPDu3WDF18sk4OWKjSDoDASm+Vc19IVq7DlAPPrelBywMkhmv1cj83ePRC+B2nY6LnR2LohlcnHpginYi0JsG6lk6i+VZyPfT7tiFZDzcOS0QX+s3bt2kV2djazZs1i1apVHH744bTbtQt2eRMP0tOte+iYAJzcAruq7019yEyBib2wihxSLa0uIVKtl7Ar56Oxks8HQkAASyDPJbqGSGUWYBdPvbBWwiLgjwm+xwJsVbVVMfediyXaR/r3PPXUU4waNYply5YxYMAA5s6dy2WXXRZ9yZFHwiefwJRF2Apssctw1tEm4HiiK81JlQ7ylkJEO+BqrAxvXfp/i7CZNCOBM1Fu4WCXh/Wvv0+Z+vxNUhZwAWX/pLtj3UXV/Zl3xdYVGE7Nh+aEsBZBCBuY8W9gILjx8NJL7Ny0iaeB9957j3379nLuuTCy507a/vNJktPT4f/+z3bTuze0aQNJ9X+dmhOG/+yFQfOWcPz99/MiUNCuHeeffz4pKYnOqWg+DuLJa/H8HrixHvZzGjYGPQk1tg4Wjuj6wBEbseJtVYyQaVSxa2UOBObjFRkqJ0zZ5G9tl7iMfEaxr38fK219ExaARhMOX4AL/RFOOomV77/PMUBBIEBKSoBZs2BMGjaYb/rtcOuttTiOBI/WOZxzrFmzhpEjRzJ1zx7+gBVs3TFoEPPmzSMzM5OkBghEB7Jm0lKob3OxmZs3A6c28rFI/diFTVaMLa5ThF+HuUn6DnCddzuDiiucRTyFtXDBZuv/mdrl2N7H1iK4Hfv+g7Uu7sAGYmwGnuGVV5Zy//0TYPly8rGaqeeddx4//vGVDB6MxZP/AYfWYxdRJW6++WZmzZpFfn4+L2KTo5cBJRs2cMoppzBlyhSuuCKR5T+bDwWFWtmF9Xt+G+uH7UviU/ul6cglWqV0B9a1uLPypzeqtlQsuTIC6yyvTiGWDAbrBquqcyCElbGILF3WnWhl0xJvPyW2YM6aNdCqFa77IDZu3Ehe3qdAS9avzyEn5yPocRj06MFgYOTIkYwbF3Os4xI47HqwfPlyFixYANgwkW+w9HUwP585s2dz3HH1uij1QUFBoU5+hRVsmUfiY7il6XgP64cHO1HWZchyQzsNm0QZK9E/30uBqd7tJKpuJezFkumRYkN/xYpEAkzEuqhSYdtWOOkkOOUU+Otf+elP4a23NgMTuPTSUubPD2DdSuPtSJObxqkmCRss2579FpcOOE3jN3XAKsFaDQ9gw/6qrsUiTcF/sU4EsDkGhY13KNXqis1AngiMwbqIaiOFxFuyaZTtRoudxR+0Y3jpJVi5Ei66iE+DQV6/6y5WrlxLenobLrnkEk44IY2MjADQrw7H3DAcVsijBU2/CEljaWZBIQn74yil6iZ0TeRjpbbPJVpATJoOR9nf94tE+9ebothlKnthhelupc51hhKWDvys3H2RzzAAJFP67LOEP/4YFixg0YwZ3HmlzTY+7LDDuPXWW2nTZn8da/WSk5NJTk6mtNRCgAMe8x5LQQvvxtPMgsIFwFhs3HZNy2nLgSkfmIINVoeK6zY2JW2wIZ2dvP9nYlfa8UYU7U852IzoYcBd3Aa8s307nHYaY8aNY/bs2QCkpaWRmdnYx1rWvffey8UXX8yUKVPIz4/OL+mNrfzcq5GOqylrZkGhK1bHJfEKi4nbiS0R1YealQSQ+peHFTJ0WFBYQNlFfZuK1t7Wzft/Gyx53LnRjqi8devWkbN9DUNYwB6KWMsn7MrKImn4cAA6duzIyJEjq9lL4wgEAvTr14+MjAxGjRpVJigchs02Su9RPnkvzWyeAlgz+HhsWGl9sqa1Xel9v573LTXzAVaiITI+vyn2HidjSdhx2NBmiH6Hmk4X5KWXXsqb/3iKBZQyhwAXksw//vEPvuetZZCUlNRkksiVcc5RWlpK7KnO/6SDwegaDQI0u5ZCfelPdETGPqxIXh6WeC4/AUr2nxJsvPwCbEhlU73eOR3rxuyFDTNNockEgsJCePBBvybRdw89lCG330FrbIbD7cCwYcNIPYDWPg4EApq5XAPNNCikY6MsajMEMQ1CA6DoWoqBEDtI50kCwTzbJcXYtP90mswf+kEpMoQ0NggXYkOEVzbKEVUtMvs9BZvw+OPGPZw4iouLCeXkkPbQQyR99RWkpXH6I4/AD+0CaCDRlcvl4NUMu48cVsFxMVZSuJISvnG1BJ6DD7bD1b/nVuADSnmetXQ+qdSqaAR6YJPZnic66UfqXwmWQI4tXR3GFrhpavMNkrCVyoYBV2FzWppe3umuu+7ijX//m+fWrqXHmDHWYujeHbJqv6COHHiaYUshgK0clUtNr+RLSx2LFuVQMKcQPmvPQmzK/Ed0ZlAHGPQBMGgldLJ7rZtpQP0efrO2FwvmYSxPsBRbBKkpOwzrJhqOjfkfQuX1skqw6qKt2R+r/IVCIRYvXkzqvn0MBbIXLmTlqlV8DHQtKYGdO2HnTlJSUhgxYgRpaWkNfkzS+JphSyFiMTYhqLi6J/pyc2HEiCTWfXkquFf8joskLLX8dBIEnj4fzn3eu3cq0VHRUnfLgWOITjg7EPI3v8GKMEYuQGKL2JW3AyvPfQzwTBXPqx/79u1j9OjRdFm1ireBm5zjb86Rj/fJeoXiOnTowOLFizlEq9Q0C82wpRDRHbgXm+E6o/qnvwDuXQhvCxN2DjvpfwSsIswaFjOEa8MXMdVNZThDsAltc4H/Ay7DrhCl5mYBL3u3d1Axj9CUTKJigcSxVD1FagWWBzkf6166DRs6Xc8BobQUnvkjfP01bLG7UktKuGnLFjLDYQJYMfjeWHvFAYTD/AdYlpfHbbfdxrhx47jooosIBGpwbFuxP7Ni7E9mGtZ4kiarGQeFTtgaCztIJCgUzoK9f4UwmdgkeYAlBAIzyMxcyNbAaTzBRYwqHU+fPb3JzHyApKRV2OIjkZEmmSj5XJViKpadmIeVEWmqWhA96Y/DLgJq4mtsGtUIrIVwSb0dWSgUIn/fPlIDkBYqhg9fhsWfwuJ8cJbynhLz/HHeRiZ+D9fqQlhZWMgTjz/O3r17ueiii2p2DLtC7PvLPlJLU0nPTLfYp6DQpKmQeIJ+C5xAS77mNeB+795VtG37GW+99QqLFt3NokUBZs6czimnnEJOTmwN/mux67CmvlBLY3uZ6Apnke3eRj2iqiUBjxJdraw2I4qOw/II36nH4zJrVq/m22PG8OSpR8OPj4cf3Qa/eAKSqmi5tARew/+Rbj8DZhKdY11T61nPcRzHAxc9YHM7j6jljmS/acYthUS1A0axHVhHJjYoLwjM4IgjMhk0aCwDBvSnQ4cOAPTd14WS9QMIhgZg9eWXY+31DKwssVRUAMz2trWNfCyJ6oUlg4/ARpvVVmYdX1/WunXr+PxzS77v/PJLen7xBVltSyEvGVqvhXARlc7fGAQMTIaBY6GrFbLrPHY5SbmbSfsYtm3ZwowZMzjyyCPp2rVrQsdTTDFf8iU7dy+AtTOg/WjI0GimJs01e7903gJNlWwnOudK3U9+EnYQ2V53EHCPPfa4C4fDLhwO+3sLnxt24W5hF94Wds49FrOf3s653fvx5zqQbHTOtXNV/x6a2nadcy7sbU3H7373O4ed9d1wcAXgwuBcGs4twrnZOBfEOeJsf8a5cBvnwmud/7OFp7rt2bgB3XAtvP0+++yzCR/PihUrXIsWLdyN4FxysnNz5jTUjy71RC0FzgS6YKNENlV8eNVquO9ymH0h1uf7K6xt7QgEqJB0C1wRgBN2w213wqhFcHHkke1Ylu0kbH5EczcP63oB61bb14jHkqhriQ4VHUKTyA85B/fdB6tWAXDS8uW0wYY5QMxYpxLsq1tK5Xn6/2AjfG8DOno/W6AnLQNH8CtWM4sSHoIy5SKq07VrVx566CG+euMNrnj1VW7EBoRL06WgwFHYH/rfiBcUSr7ZQt5jj1Po+mEZsqeJrtYVo6gI9u61nHL/LfDLf0LhzpigsAf4J5AKnIyNRW9uU+/3EB0C/ClNf7huElakLuDdPhM4sVGPCIBQyMZHOwfhMLz2Gnz4IQBDsV6gl4mm7POBgjC0eaXsH7zDZuv4nZpzIbAS2lwLwY6RO7uTzkDO4UtCXlCoiaysLKZOncoD2dk89OqrXIqCQlOnoFCNT7CC27u4B1vbdmv8J779Nlx1lZXeOSpE5Yu9Pwu8g12Wja3vw23ifgG85N3Or+qJTURX4C1sKUywCrtNwObNtuJZXp79f/v2Mg8HsfFMDrsE+SP2tXyFsgOjC4CzgS9i7msNvAlEV0/+ATYm6UPq8jubiq02UtuEtew/CgrVKMTaD44couvcxigqgnffhffftzHg7wM56TDpVBixBetqihXpKnnH+/dbHLy/hlJszncuVlp8KU2zhHU8x2DzBg6jYUqt15xzjrlz55K7dCkTNmwgNT/+STpA2eLb3bEBry1i7luGDYH4grK/kTYlJZTOmAFHHgnHHguBz71nxkzynD8fWraEiRMhwVnOrfv3p/VZZ0G72NIvK7wjOJFo4JVG19hJjaah0Dk33MVLKL77Li4QwE/exW6PP/64c9u2OXfIIWUTdod0s/vDj8fdZ3Qb6Jzb2wg/7/6yxzl3uXNutGv8xHBNt5dcU0sih8Nhd8YZZ7jDwO2OlyiuZAtHks0x2/Vxvs+AawNuLTh32mnOhcPOuanObcO5brhnvOc8A/ad37atJgfv7S/Wrc65NOfcknr7jKTuDtZL1BpKxhLN84E7qfGM2fKJN7cbuAIC39TL0R2YHgX+BywhbguryWkD3A18hnW2/BFr9v2Ghmgp5Ofnc8stt9CtWzduuOGG+LOEH3iA3XPncjNWmD0QgBNPXMSlE6DFLcTtzXkDK5BxG7ZCMljLocS7b4N339LKjgu4Duswup74qfQHgA+d426suykhcWdBn4Pl83rGeUwai4ICYL2wkeTvr8o8kob1LOfQmnx/WcRCKs8ZAOECyH7Z8shtq3rfUixH0Qp7cisOzF9JHhUn5n0AvNAIx1IT6UBkzHx77FSYiv3G12K97vWwQI9zsGMHJJXYtJdAG0KhMPPnz6dPnz72nJwcwvn5bCcm8TtzJtmvvcZLWOcbwPknwRkDKPs1adfO78b5Cvvkc4GSkhJ27NhBy5aQ2goW0YHPvMENeXl5sK/iiK8S4HUgXFTE9Vu2AAWEdsGOcDS0z8GCy+01+hD2Yt8TsO96BywtPrRGe5GGdyCegfarkVhW4BZu5gl/KNE7RBfZiWMblio4H/hTVXtfBxyLjccYDNyELed5oLkX+Gu5+/LiPbGJmUB0WOwOLKl6DFYsEexiIeFr4coVFsI550CHz62ieuAuMjMv5rXXXouuWnbHHeQ8/TQn45cmgpwcHNab38q7K/la7K92j3dHIACPPALjxgFwEZY8zgJWf/YZp512GtOuKOZn16fyNE9T4qWa77zzTh5++OHKj/nDD+Goo4BccsJw0s66rm79JPBr7/YRWM2xA2ehnuZEQaEaaV0602XyRFrMd/DFu969S6t+URibllDteTGERZAk70UHwoicWNuwAPkJkN3Ix1Ib24DI7zQHS7mu9u47AZu/Uls7gP/BEgfLQjBwIBwaWQ+4B6WlpcyePZu9e70W1uLF7MnOZiPRNuhx2LzpDO//AaBbTsxb9OsHo0fbvrvYsWZ6G0CrwkImXHABvY8tIdAlhfb08X+mzMxMqlRcDNnZzMG+7V9hrY/EbMZaWtuIrm3xMYSz4W0gfAic5KquEyiNRkGhOoMHwz/+AVdPgy9+3kBvshU7iewjUoIgNk0RgEr6ZPeneBOWPseuTQ/U8h0LKFsSDqxzZA42dLZ2i7o754C1BAJT4dlSeCADPvkEhkQGhDoKCvK4/vrr+fLLLyvdz0+A86p6owkT4C9/qfThXr168cQTT9T8B4jxd+wav3qx349PvVfOBhczXDYE3IE1fSagoNBEKSiU0R94EXgCeHU/v3cIW8Ddhuw98wy8/JwV4jtswAD49a8beYHxL4HplO1j38mBGxAqcwJW6XR0rV5dUlLC9OnTCQZzueuuZ0meEoBjg3DooTHPehT7fsWf8zIGuAHruqxg+nQY6T3Su3etjjERC4HvEe1Iq5rDEvILvf9nY51Nudb4ugFrMASS4OK7oO9oSNapp6nSb6aM9li1yo/9ewoKCtm2bSMpKSn06NGDLVu2kJKSQseOHWnZMv6olFKiJfA6JPzeDpsglAp0YdWqXF57JZdbAMaOrTjCab/IxxKERVgJ8Fep2fKlB4oOREfxH4lNs6qB4mLYuhVat8a1aMHnn39OMBjEuTNgcEqFRdR27VrGN9/8l5IS+46UnxJ3JPBdvBZiMAhdu9qCN4EAfOtbNj+gjrKysujRowdbt26lpKTi7zQbm+xWuRA2gycf++6+ByXv2Rc/9qu6Bqu6mtIaOnSAX0zychXSZDX2mNim6XoXGa/+wQfJrn37LPenP/3JrV+/3vXs2dNNmjTJ7dy50xUWFtpY7W7dyowB3wyuD7ifTK3N+Pihzrkt7tZbb3Bp4JaAc2PHOldSsv8/Bve6c26yc+4w51yrGvwMB9r2N+fcTm/bU/OPafly57p0ce6uu1w4HHa5ubkuNze3TKHEWDfeeLVr2xaXlIT7Nrid5bY9sXMKunRx7vPPndu507aiopofXxz79u1zmzZtcv379487X6G6rVu3gNu2rY1zLsvbUpxbj3M9cS4rZmvt/RzTptnxN8r3WGpCLYVqdCop5ZxduzkiKYnOnTszefJkunTpQlZWVqUrUDksbVm7Em85wIuMGNGCSy+/3JZ379NnP+cUdmHVcxZgs1mzafpJ8JHYqJaXqXK4MGADjc8mOv9gGJFuu4QtWwbz5sEZZ0DbtnD22TB4MIFAgNaty45YKi0t5aWXXmL3bjuuBQtWkJNjj6VgI4UC2EDn17CBRaXAhAkT6HP00dZSaNWK+tSiRQuCwSDnnXceixYt4o033kj4tROBo/Id6f/ILTuFYzv2VYkUXTr9dOjWzW6fcEK52czSZDV2VGqabnDOBZxzODcTKzX85z87FwpVnJUZp6XwNbiO4C6uVUshst3unAu5hp9VG/beJ3Zb7pzLqMOxN8Z2l3Nun3NuSBXPCXhbB+fcV7X7tMJhFwqFXPjee60U9IcfVvm8UCjk9u7d6wYNGlTmSjvgbafFzDbeAW4QuExwgUDAPf3007U6xpqaOXOmCwaDCbcSnqlqBnXA24JB52bO3C/HL/VLLYW4LsGK1U2DYV9ZhbCZD8E578FDD9mVWxXaY2Xv6lY+7Z/YlfqfaNi6kt9gy5LGtgQieYSmLIjNOm6JDQzoXs3zRxAdJ59KbX87mzdv5uqrr+aUQYO44r//jRlRVNbq1av52c9+RigUIhQKsXFjtLLuj4musxZ7FK2wWr0F48YR+vnPGTp0/0zsGjZsGG+++SYPPvggr7/+evUvOARLhqyn7DiDLsBDQOYZELgahg1riMOVBqagEFd/7CSTaWf4SZD92mry3ttCz/z86JSbrVthwwZbFD1GejKc2JO6DXPnSyyRtxzrZOhB3ev3R+ZFxK6FvJFocb4DRTvswx2MTS4bTtkScBEdic5YPhKYRK0/Q+dg82ZKvviMjRveYdfo3jBpkvdgIfAVO3c6duywe5YvX87bb79NKFRxdNZAbFUNsPAbqVIaTEpiVK9epAwfbvveT12G7du3Z9KkScybN49Vq1axcePGuMlnXzLReWetW/tzJOgBfBtoNQL7rOWA1NhNlaZrr7OCddb18NOf4Lq1aePWrV0bfcqVVzqXmelcIFC2Cd0VS7oV1Ee3SIZzbqJzrj4SdDucFagb65xr6W0t6uEY9/d2vbNV7KY7537uLDlc4ip2H/3WOZfnbfmuTl1xoZBz3/mOCw1r4fZswRUWXhfz4DLnXHt3zz0tXcuWtmVkZFTa/fJAzHdlBriW3tazXTv39erVzuXn1/4466CgoMB9/fXXrlevXlV3HwVwLsn7GS680Lm8PNv25jkXznPOFTTK8Uv9UEshQceeCGnpRbR+8XFIbm93LlpUsX7MaVjOswNWWqfOCrDZofcD47FukOrMAFbGuX8fNvJ8CxVrFTVVbajY1fMV8DjQ236UZ/9m03jbOCtZ3vbb3vOOIVogojbygH+xbFkhM991nDVoFb1Gp9Ey62IWfdaSDz64z3veN0Aus2aVsreKj7V79+6cc8457J41i/uWLgVsoG/kJWmBAC4zEzIyKttFg0pPT6ddu3Zceuml7Ny5M+aRAqw78xDgNPrHvmjUqHpPgksja+yo1HTtdXbVmeT8K8/dONe7iiQbOPdMQ10dB51z91ZzzGFnV8yTG+gY9scW8D7zyOd+uHPuLOfcd2O2gc65FOfcXOfmz3UuPd25XkHnTmzp3Nrl1XxGiQuHN7jS0iz38F9wyQHc/97EhUv6utKS3e73v/99pVfSSUlJLhgM+ltSUpID3PgTTnClRUXu6p/8pMJrAoGA69Spk9u0aVO9HX/92eac6+GcO881tXLiUv/UUqhUOjbB/2OsmHBjTB6LOAIrWFxdsbzZ2KzjL6p5XlPVBSv4fBH2+V/q3e+ILtYD0eqlP4aBA+CdtyA1COlJ0O2wejua7Gz40Y9g4Bp4z8GQG2BT1tdcyqms3Rx/NnJycjIPP/ww/ftHr6cLCwu5/PLLYelSK00Rp7TFjTfeyHe/+106dmwiq7uV0Rar5NeaJrEutTQoBYVKBYGjKbMWQBAYQHRs9iaiQ+LbYGXh29bgLQqxGZ9h7G/tcKLVzMpojZVHi/fr+ppoYeVFxM7GPnAEsA81E0uqH4F9oEEsKZ4L7IKCHPu8OnaCrn2AMLRKguPGEn+9683YZxPZdydqclILF8GeeRDabb+B5BVQQAFzmVtp51sAODIzkxFduvjzS/Lz88nMzGTvhg0s+/hjdsR5Xd++fTnmmGMSPrb9K4Xalv2QA09SYx/AAaUlVidtvredHvPYRO++mlQgWI+V2hmNjYD9rDYH9VtvB6OxIjMHonQs6LUCZmGT5yK+xlYIyLEBWScAj0wl+kt4nMqvbe7DH1pMzQvDdcXGZfXH6hHNT+RFpaUwdSpcckmFUWmLvf08X+MjEdl/1FKoiQA2GTbiu0QXjRriPVaT1rXDpgMchQ3lqzD9IQj8CMtcR+J3MVZQLdI6mM9+nVMwC5jrHVa8UaA1dg7WMuiNnfyXAv/Ghp0WE+12PxQ6dIFrJ8DYb5FYFr/U2yZgw1YTsRzcK/A8BObnkF5QQErMUVQnDDxWXMyy4mIuomwh0DBNf/aHiIJCtZKwQdklVFim83veVlsBb9fjsZLCFSQDV2GrU0WuOvdiE9oaKW8wC7sAP41aBIUg0eAWxuZNnI8VoCshunLMP71/A95rgkAf6DIcfnk71S/OEtl3GOv6OB3oW8XzI891WBfcbfC0xYYS74hbk9gfSwh4BFuEdArRoJCcnExycjKl5VoPAW+/qiItTYWCQrWOxvrpf0e9N/x7ATOxru4qLQOuIHry2lj10xvSZcCZ1HKBuF8Cp3i3ZwC3erezgQux/qGIDGz47XjvDSN5gUS+suuxleDmJHhcz2ALBS0gZt0zsrEf9wjvaA8v82ji0tPT+fe//81HH33EVVddhXPRNsex2Lzs+kuPi9SNgkK1WmMnp2rP3DWXgXUdVSqMzWguwGrVh6t6cvWKvN21w3prKpOP5Te6AIeWe+wQb6uVdOzknke0PsIXUBSE5QuhXRH0zvLeoAP2uY+k6rkZhURLOBfYXXnrYNVC6JldyazyEuyDKLb/rlkAOxdgn7E3k3dX9Co+0su3EpshUdMVJJxzlJaWEg5X/P21aduWEf37E+jUAN8vkVpQUGjSSsBfF7qOAQGswsXpWOGd8ksqx1qP5TiuBu6q+9tGvQB8BLxPtNbSLyA7AKeVwlk94ZHhwC1YWYoA1Y+F2ATchrWmvC61JQ5OCsPvHVwTb2JVHpbL2GT/vSMMz5bLGoTsMuA54DFgnHe3o+ZBoaioiB/+8IesWLGiTCsBgDFj4JVXtOiMNBn6JjZ59biyWRtsGkO/OI/NBl7H8gQp3vMqGyFZii1Ql4oFmDLn7b5YIHsFuxq/Bpvx+y+iff0l8EXYlkI+OQTt28D0adC/q3cAhxJ/iOkW4C/YuN9OwDpv30uA7VBSagXZPsEaAWGwa/w/4NdAeh9YUQBbd0RHBy2mzIJyzjvaFd7/l5Z9uMZSUuCaa0J88kmIRx+1WY5paWlcc801jBo1yp7Q6MutihgFhYSlYP09hTTuRLY6aI2tNBnPUuDP2DyMIVhVjTSiF/RJREdXhbEF2DOx7n7/ij4FizjXYfmBL7AA8SnRoBAGMuCrJLsMHwL07gTXXoV1GVXxlQxvh8I/QHIPSOkPRR9DOCf6eAG2NPBqrKfKAfnFWO1Rz4fYogWfQWmxxY7UmHctxe57HouR9SE5GS68ELp3h8ces/+3aZPK1KkX0adPVQlwkf1PQSFhNwI/AL6PjZ0/yJyH5XTTsB9vAn6XOwCDsJGiKdi35g4sDiSBZZ37Atd7L7oZGyqbh0WNSEXWldhQ2lfhmHY2xaAzWE2mP2IJlh9UfoxrscFKF22EH2+Fi/ZFL+fB4s06bzePYYOYRpXbx3bvsErgPeCn2BCCU72H38IaSV9VfhQ1VlgI551n6/KEw3DTTXDWWfuYNu179Os3gb/85S/1+G4idaOgkLCuWEuhuuGQB6j23gZ2Dl+N1aGLJKRjF81Kwlu+IBnryhmInYnzvRe3xj6nMDYFuQMWcSI7Ggwt28es2pWNZbaT7DF6YoM0F1Km+6xwHawMwyfFMLDYGiCfx/lZSrCT/zooXWGdSxnengORwz4G8vJgxQoboxQpQTeXsnGmtvLy8pg1axb9+vWjc8eOtPsS2m6wx/buhezsMKtXryE9XS0FaWIaufbSAWa3c663a/yicQ28Lce5DJy7EedKvS2Ec+Hyz23vnPuOc+4V51yuc26Ac+4k51ypsxLdked9x7uv1MVfTW6jc66ds7Wgz3bOLXbOfe6ca+2ixfGSnPs04Fw6trJXpHRzZZv3eB64o8F9P2aFM9cO5zbgnn8uugpakrcFElx9LJEtKSnJ3XPPPS68b58LDR7s3o28R8DWZwbcqaeeWulaziKNQS0FiQoDD2J9J3djo0GrnFW1D0sm/x3reNkKG/bBS9fCxB4w9AHveb2xVkD5ZKrD+nlme/sqwZIbv8Mu5wvsoMJYvmO+95REphd7g7XSsE6tNgMHwpVXWkI3HWuwBJYCjyc8W7mmwuEwr776Kl9v2ABbtrA5clhe5AJYsWIF06ZN44ILLmDMmDENcBQiNRNwrvwYOalcLnA81rnd1Beyr4UQlgLYgY3SaVHTHbSEhUnWKf9/98PpF5d7vIhod5A3EqlwCpS+bnenEu3HCWFxwnlPPZ34c9GCQciMW0UQCgtxxcXsBZJOPpkWb75JIFCIRZaWvPrCS/zw+98nn7qNLqoPjz76IBdfPJl9+yAYTKFFixp/+CL1Qi2FGmmJDV15G7i8kY+lASRhA3VC1GKBoBbASzDkMKs91zZeCeinsfGiAFvALYc/b7UJ46uxqQOReRFfYbWlIoHhm0redvBgePbZ+OP8f/1r9j31FN/FJo8/CsCdWJm715mAFbW4DnijBj9pw7iDnJw/cuaZMHz4KTzwwAMENExVGoGCQo0EsSRohcp1B4cAtZytPBAbnjQQ0rt7SWiwkUgf4880Zi7W3QRs3gFLv7QYsQKbMLcI+K/31G+wHHXkpRWONQDHHgsjR1qJ6tigsHMnzJ/Pit27WYmtbhYZHrBs2XY2bfoCeJsuiz/nKKL57mTsN3uEdyjZtfkoamn58u20aLGd1asBlvDmm28yfPhwunXrth+PQgQlmmvnddfoyeAmtd3rLHlcPmG60znXM/5r/lVNori6LSXFufnznQuHbYv1/vvOBYNuWkzS9+STT3bhcNhdcskl/n1ne8nn87wEc2twl3n3faceE8613Z5++ukqvoMiDUMthbp4HBsWeTv+hNkmyQEPY2P4bydmKGgNbAGewpY9OC4Z+AXRJsFoKiaRZ2EF5vZE7/o7MM+7XXHxseodcgj84hc2AzgYhMMOiz8TuH9/+Nvf4D//gZkzAfjss8+45JJLmD17tv+0hdjabkdiVT1SiI7AVceNNFcKCrWSCnSAJXvg7SKbq9VgIrPFWmAd7IVVP70yC7ByDrdU8ngR1lXTEjsj7iValLUNsCcIs9t6BfLSgbOx6cjllWJJ+CVYHYsC2/ceLBXzQg2POz09mkju3dsWsEmvOuFR0qEDuWeeScG8eX5Q+Prrr3niiSfKPG8jlv74NzYnLkIjL6Q5U1ColXHAErjjpzD9+QYpoGqSsCm5w7GBlb+hTMmGRAWw8j/F2Ak+nrex0aG/xuae/QxL9m7D6hwdMQgeewUyI73zlf3Qn2PrPczDkgJFNpLpMsouqJaoCy+E22+32ykpkJZW5dMBFi5cyHnnnceuXVW/YTI22El/BCJR+nuold3AXGi3vQHfYxB2JT4IqyfUA1tasvyJbjEUr7OL8jZYgf7Yvo9solN007DJxUHscvhjILL+/BxsBFA+0LE1DJ4AHYL2o7YEUg6HTodiX5lISe8gNk84pkIpG7z/b4XiQhvoM4vEKoMcdhgcfXTZ+447zooGVWP58uWstiwtK1euZNOmTbhqRlt3w+ZZ94jz2LFjxlCclcU777xDSUlJhcf79u3LsGFDgQ/Izd3BzJlWwkLkgNfYSY0D0/5INN/hosnbSCI1HGe70rldONcT586k4qzj/+HcMd52Js7lePeHce7kcsnbJJx7H+fcYOfC+2KSuOWTyEXOueucc7c4m6V8XfyfYSfOHVqD5PFll0XfM3ZLwPTp02ucyI0kmuMdS/ill9yGDRtcVlZW3Nded911LhwuceHwcW7pUlxamhLNcnBQS6FG8rEEwtIG2HcSlgWO1MIZQsV0ZwDLKdwCy76xWcduoaUdbsPm1p2PreA5DLgJu/pfE3P43twxB/wW2NoZ7r4bMjJOhsBF1jChDQRS47w/2OzjT4CTsRVsyq138Clwj/cGxdhEuKpcdx2M8qrWHX54jUtIr127ll/+8pcsWbKkRq8r4xrIGQQ33QxHHAFX/wQCI6FDVgceffRR3nrrLR599FGmT5/O0KFDAejfvz+BQOR3thBbRa5ii6I2Ro8ezbXXXqsZztIoFBSqVYRV9nRYtvRV6q+GZjLWn5OEdcWcii3/Wckx5DrIz4cOr0HOl7ZejQNaYSWxlwPPYl1IbYCXsZyAJ5QK276BjAJ7+LOW7Vh/eDql5wCtRmIVSvdgZ/NtlE25Rmpnr8D6g47FKuh9A7l7LTGN9/Cz5V7q2e39JB1TIJiWAa2zYOJEOPXUik9O0M6dO3n++efjdvFUp8COnqwxbSme0IJ5D0PqkVjFWDLIJJPvfe977Nu3j7feeotJkyYxfvz4cnuZQEpKV7p1+ytFO3bAnj3QoYPFwx1lI2Iq9onlYUMGwNZVaNeuXZmJakOHDuUHP/iBJq9J42jspkrT96FzrrNzrqNzroOz4mz11UXUzzm3wTmX7W3FlRzDPOdcF+du6+hcrw7OfRF0rgjnsr1tDc4diXOtve6PVjjXngpF475OwvVrj7u2Iy7cCbf7hf+4HTuyXSiU7ZzLc1as7m5nRem6eD9zZOvjnPuhc+4o51yaswJ23mO3ZjjXEdvaVN499GNwg5JxW4fi3PXfcy4727nCwjr9dubNm+dSUlJq1T2TBq4juBf/84grLc1227dnu9zcyO8ielz5+fkuOzvbFRUVxT2GkpISt23bNpd9000uOyXFZb/9tnvzzTddcnJymfcbC24LuEti7ps4caLbunWry87O9recnJw6fSYidaGWQqVKsOm1c6l41VwX/YkuadYN64KpZERNKAT//S+kzIeTtsHAMJyIJW9jS+PkY4ncPO//e8rvyKSnt2DixDM4In0XAb6gbd8u0D4dK/IQWTxhHZCD1Z6OXfVtH/AZLPkGlhVBVpF9JDlYb1JVOfcewIkwLHAcycHDSesBDDsGGnld4iLssItoTTDYiQ4d4j8vIyODjIyM+A8CycnJdOzY0ZbWnDIF+vQhK7vifOiULl3oOGkS4wNrKCUbGMHQoaPp1KmTWgXSZCgolBF74i/CBvWvquf3mIiVIo15P2+UTOy7BwBKSuC226Dlpza76gdYYbgRxF9HoBrt27fjoYcehPZLsdlsbbDhSVcSjSTjqLBmhAOLPIvhJaw+0RAsZqxM4I2PBp6EKwJXAJNrfuAHiu98xzaAOEGBAQPg8ceZHHyCyczCxgl32Y8HKFI9BYUyVmMlPsPYJKxNddzfBGBaufsOi7m9CfgZvFRE6ClLYZdihaNTwMY4rl9vxXjAZlq9QGLDO9tg0wViZ1pn7IBWk7GM9AasFFykRHXECix/4LUSQtiyyF9gqZRVWJDYkMAxtGwJ998PQyPF8Y5K4EUN6+qrr+bb3z4Om47eDTiLo8sPg60H/fv35+WXX+bJJ5/k9ddf5N574aijICkJLMIfhS1QJNK0KCgA+GU4V2BdKaGqn16ljkTrSPQFN8QuxstU2l7n/bvW3m9BIe51u7eYch1VKViM2oD1ZL1VxVtHlklui3XZnIIloXdjvWGBQgj+L+YFW+1+v9A/VJgHEcLmM3yKBYbIwVXSRUVGBnTubKOI2rSBk0+28hQNJA2rgLoNC3Wx2rVrR6tWrdi8eTMpKSl07tyZ4447jjPPPA37gXoBZ9AQRS2ysrI4/fTTWblyJStXLmbSJOjXr6v3Xj29TaTp0XoKgHUVfRsrzbC3mudW53HgLO/28+BusNEs/4v33DCwB4rAFUbfOVJpggBWgDQJax0UeIdambbYcsk3ApOwgDALG7r6JTZ99yPKLq35JTaDq7KTPN77lhITOKpw4onw4osWFAIBaNUqcnncIErnz2fvuHHcWVLCH8s9dvfdd3PhhRcyfvx4evfuzXPPPUeLFi1IS0vFfqgkalEjvEYKCgooKiqiVSsIBpOBTFRZSZoytRRYgF2CryfhgLAFmwGch9/zsharFFGxVHQup66EXt5l7HLvGWcQU2EaO020Kv8+kURu5N/KpALnAp29bQtW0Aesu2ctdimdipWyiF2TZjuRbGvtHXssDBtmtwcOhLZtazzfoLaSO3em7RVXkD5nDixeDEC3bt0488wzGT16NB07dmTy5Ml06tSJtm3bxiR0988iNtUlqUWanMYe/tT4bnfOBVxCQ0jD2FrFH3ozhDtGh1s+i5VfjmzEbK+BC3mzZx8EFwQ3s5rZveGY11T1PAfOtcW5L71jC+Hc5BrMIk7gGELxjiUQiG733ddYvzzfLbfc4gKBgAsEAm78+PGutLS0sQ9J5ICk7iPWYUN5pmGX1FXYC/wYu/qOLADjzZnKxl8+hh3YeJ5IH/cwLFf8MNa9/wVW4i62F6e8/2ADfX5HtJxzpZKxunmRC9IVRGsa1cHTWMMCrPrSn/AS4Ckp8OCDVrUUoF8/OPTQur9hHaxdu5YNGzYA1p9/1FFHaZinSC2o+4jeED4ENraK5gDjnUu2YqNvZhF39E+k52Yz1hHVn+i0gXXYKP8Qlv8tX4BtJ9a7E3nrjVheeSsJrh1cSvz1i+toL/bzkAZZ6em4Lj2tWygtDY4/3oZYNhF9+vShT58+jX0YIgc8BQWwq/0LsSvt/xH/U/kd8FcqXx7SMx07P7+HlTRwwFSi5YfieQq4A8tJpGIDWa/1/t+wadCqXQRcAHA4JB01kJQ/z4QUbw5DNWsaiMiBSUEhohAblXovNmt4OPBP7DIeYD7lhpWaAqybpSs2AnQS1tXSDmshzMA6pbYDDxD/JD8Luyr/J7ZE8qXAGPZXKjSO9qkwpQepyf1JDQyyJlD37jaSKKivjMjBTDkFgKIiK1EQqbR5D5YUGEO1E5p3YDFkFPAoNmoz8oE+hZ3gqxKMuR3CpjTNITo9IUjZ3iznPS+ADahMuNfcf3KwmicCg1vD3PHQ4mysCSUizYUu++J5GKswuqH6p7YB/kF0bsHtwEzvseqW4OmFJXLTsbTAVTGPPQ78C1vWuG/M/YXA1dgUud9Qg6BwJ3BiJ+BJKl9+zZMRhLTWWAVXEWlOFBTAzqz9sT6cNcBGCG20UULVpBB8e7AlkOdjsxMq04FoovkwrDGSh+WwY6d4lWABIAw2r6AvEOgGdKaIaPm6hI0Gju3svWPbmr5aRJoJdR8BuCIoGQNzlli9upCNFhpLzcvhVTfx90rgfu92AOsmug8rvVeCpTLmYJ08Ie/xpDFYZdTke3BcaxUrsIiecEsh2dsplS2eIyKiloIJBCH1Cjh8i61gFraT8WVU3wVUU6OoWCh79OzZTH/3XQC6du1K8JJLSA4Go7+cQ7GRUUnjCJBWvoapiEi9UUuhKbj3Xtwtt9jqYcOHkzJnDoG0StZYEBFpQA1XqUwSN3kyoY8/5rIhQ5hKfa30KyJSc+o+ago6d4b27Uk75hiSSkoINGBVURGRqqj7qIlwzhEOh3HOEQwGVbdHRBqFgoKIiPjUTyEiIj4FBRER8SkoiIiIT0FBRER8CgoiIuJTUBAREZ+CgoiI+BQURETEp6AgIiI+BQUREfEpKIiIiE9BQUREfAoKIiLiU1AQERGfgoKIiPgUFERExKegICIiPgUFERHxKSiIiIhPQUFERHwKCiIi4lNQEBERn4KCiIj4FBRERMSnoCAiIj4FBRER8SkoiIiIT0FBRER8CgoiIuJTUBAREZ+CgoiI+BQURETEp6AgIiI+BQUREfEpKIiIiE9BQUREfAoKIiLiU1AQERGfgoKIiPgUFERExKegICIiPgUFERHxKSiIiIhPQUFERHwKCiIi4lNQEBERn4KCiIj4FBRERMSnoCAiIj4FBRER8SkoiIiIT0FBRER8CgoiIuJTUBAREZ+CgoiI+BQURETEp6AgIiI+BQUREfEpKIiIiE9BQUREfAoKIiLiU1AQERGfgoKIiPgUFERExKegICIiPgUFERHxKSiIiIhPQUFERHwKCiIi4lNQEBERn4KCiIj4FBRERMSnoCAiIj4FBRER8SkoiIiIT0FBRER8CgoiIuJTUBAREZ+CgoiI+BQURETEp6AgIiI+BQUREfEpKIiIiE9BQUREfAoKIiLiU1AQERGfgoKIiPgUFERExKegICIiPgUFERHxKSiIiIhPQUFERHwKCiIi4lNQEBERn4KCiIj4FBRERMSnoCAiIj4FBRER8SkoiIiIT0FBRER8CgoiIuJTUBAREZ+CgoiI+BQURETEp6AgIiI+BQUREfEpKIiIiE9BQUREfAoKIiLiU1AQERGfgoKIiPgUFERExKegICIiPgUFERHxKSiIiIhPQUFERHwKCiIi4lNQEBERn4KCiIj4FBRERMSnoCAiIj4FBRER8SkoiIiIT0FBRER8CgoiIuJTUBAREZ+CgoiI+BQURETEp6AgIiI+BQUREfEpKIiIiE9BQUREfAoKIiLiU1AQERGfgoKIiPj+H+V+NTohsXIeAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x[0])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 814ms/step\n",
      "0.0010000002\n",
      "404\n"
     ]
    }
   ],
   "source": [
    "output = vgg16_pretrained.predict(x)\n",
    "classname=keras.applications.vgg16.decode_predictions(output,top=3)\n",
    "print(output.mean())\n",
    "\n",
    "print(np.argmax(output[0].flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airliner 0.93717927\n"
     ]
    }
   ],
   "source": [
    "className=classname[0][0][1]\n",
    "prob=classname[0][0][2]\n",
    "print(className,prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./images\\\\airplane_1.jpg', './images\\\\beagle.jpg', './images\\\\car1.jpg']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "# vgg16_pretrained = keras.applications.vgg16.VGG16(\n",
    "#     weights = 'imagenet',\n",
    "#     include_top = True,\n",
    "#     input_shape = (224, 224, 3)\n",
    "# )\n",
    "\n",
    "def img_prep(x):\n",
    "    x = keras.preprocessing.image.load_img(i, target_size=(224, 224))\n",
    "    x = keras.preprocessing.image.img_to_array(x)\n",
    "    x = np.expand_dims(x, axis = 0)\n",
    "    x = keras.applications.vgg16.preprocess_input(x)\n",
    "    return x\n",
    "img_paths = glob.glob('./images/*')\n",
    "display(img_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for i in img_paths:\n",
    "\n",
    "    x = img_prep(i)\n",
    "    output = vgg16_pretrained.predict(x)\n",
    "\n",
    "    classNames = keras.applications.vgg16.decode_predictions(output, top = 3)\n",
    "    className = classNames[0][0][1]\n",
    "    prob = classNames[0][0][2]\n",
    "\n",
    "    img_opencv = cv2.imread(i)\n",
    "    text = f'{className}, {prob*100:.2f}%'\n",
    "    cv2.putText(img_opencv, text, (10, 30), cv2.FONT_HERSHEY_COMPLEX, 0.8,\n",
    "                (0, 0, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow('image', img_opencv)\n",
    "\n",
    "    key = cv2.waitKey(3000)\n",
    "\n",
    "    if key ==  27 or key == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 148, 148, 64)      1792      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 146, 146, 32)      18464     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 73, 73, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 170528)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 120)               20463480  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 120)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                3872      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,487,641\n",
      "Trainable params: 20,487,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Functional API\n",
    "inputs=keras.Input(shape=(150,150,3))\n",
    "Conv1=keras.layers.Conv2D(64,kernel_size=3,activation=\"relu\")(inputs)\n",
    "Conv2=keras.layers.Conv2D(32,kernel_size=3,activation=\"relu\")(Conv1)\n",
    "max_pool=keras.layers.MaxPool2D(pool_size=2)(Conv2)\n",
    "flatten=keras.layers.Flatten()(max_pool)\n",
    "dense1=keras.layers.Dense(120,activation=\"relu\")(flatten)\n",
    "drop_out=keras.layers.Dropout(0.3)(dense1)\n",
    "dense2=keras.layers.Dense(32,activation=\"relu\")(drop_out)\n",
    "outputs=keras.layers.Dense(1,activation=\"sigmoid\")(dense2)\n",
    "\n",
    "alz_model=keras.Model(inputs=inputs,outputs=outputs)\n",
    "alz_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./images\\\\airplane_1.jpg', './images\\\\beagle.jpg', './images\\\\car1.jpg']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def img_prep(x):\n",
    "    x = keras.preprocessing.image.load_img(i, target_size=(150, 150))\n",
    "    x = keras.preprocessing.image.img_to_array(x)\n",
    "    x = np.expand_dims(x, axis = 0)\n",
    "    x = keras.applications.vgg16.preprocess_input(x)\n",
    "    return x\n",
    "train = glob.glob('./train/ad/*')\n",
    "display(img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280\n",
      "(280, 150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "img_path_ad=glob.glob('./train/ad/*')+glob.glob('./test/ad/*')\n",
    "img_path_normal=glob.glob('./train/normal/*')+glob.glob('./test/normal/*')\n",
    "img_paths=img_path_normal+img_path_ad\n",
    "target=np.array([1]*len(img_path_ad)+[0]*len(img_path_normal))\n",
    "\n",
    "print(len(target))\n",
    "imgs=np.zeros((0,150,150,3),np.float32)\n",
    "\n",
    "for img_path in img_paths:\n",
    "    img=cv2.imread(img_path)\n",
    "    img=(img.astype(np.float32))/255.\n",
    "    img=np.expand_dims(img,axis=0)\n",
    "    imgs = np.append(imgs,img,axis=0)\n",
    "\n",
    "print(imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "alz_model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['acc'])\n",
    "checkpoint=keras.callbacks.ModelCheckpoint(filepath='./alz_model.h5',\n",
    "                                           save_best_only=True)\n",
    "early_stop=keras.callbacks.EarlyStopping(patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 3s 203ms/step - loss: 0.0149 - acc: 0.9955 - val_loss: 0.1426 - val_acc: 0.9643\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 2s 184ms/step - loss: 0.0199 - acc: 0.9955 - val_loss: 0.0200 - val_acc: 0.9821\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 4s 306ms/step - loss: 0.0096 - acc: 0.9955 - val_loss: 0.0109 - val_acc: 1.0000\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 2s 178ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0495 - val_acc: 0.9821\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 2s 170ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0358 - val_acc: 0.9821\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 2s 187ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0264 - val_acc: 0.9821\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 2s 181ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0870 - val_acc: 0.9643\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 2s 191ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0271 - val_acc: 0.9821\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 2s 171ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0372 - val_acc: 0.9821\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 2s 170ms/step - loss: 8.2620e-04 - acc: 1.0000 - val_loss: 0.0728 - val_acc: 0.9821\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 2s 171ms/step - loss: 7.9478e-04 - acc: 1.0000 - val_loss: 0.0556 - val_acc: 0.9821\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 2s 170ms/step - loss: 9.7565e-04 - acc: 1.0000 - val_loss: 0.0587 - val_acc: 0.9821\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 2s 169ms/step - loss: 6.7945e-04 - acc: 1.0000 - val_loss: 0.0406 - val_acc: 0.9821\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history=alz_model.fit(X_train,y_train,epochs=100,\n",
    "                      batch_size=20,\n",
    "                      validation_data=(X_val,y_val),\n",
    "                      callbacks=[checkpoint,early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['val_acc'],color='b',label='train loss')\n",
    "plt.plot(history.history['val_loss'],color='r',label='train accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0406 - acc: 0.9821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04055050015449524, 0.9821428060531616]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alz_model.evaluate(X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 150, 150, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 150, 150, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 150, 150, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 75, 75, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 75, 75, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 75, 75, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 37, 37, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 37, 37, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 37, 37, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 37, 37, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 18, 18, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 18, 18, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 9, 9, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#이러한 구조로 인해 maxpooling 레이어 이후의 특징 추출 능력을 갖게 됩니다. \n",
    "#vgg 모델내 데이터로 학습시키고 dense 더붙이기\n",
    "transfer_vgg16=keras.applications.vgg16.VGG16(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(150,150,3)\n",
    "    \n",
    ")\n",
    "transfer_vgg16.trainable=False\n",
    "transfer_vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 4, 4, 512)         14714688  \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                524352    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,239,105\n",
      "Trainable params: 524,417\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "finetune_vgg16=keras.Sequential()\n",
    "finetune_vgg16.add(transfer_vgg16)\n",
    "finetune_vgg16.add(keras.layers.Flatten())\n",
    "finetune_vgg16.add(keras.layers.Dense(64,activation='relu'))\n",
    "finetune_vgg16.add(keras.layers.Dropout(0.3))\n",
    "finetune_vgg16.add(keras.layers.Dense(1,activation='sigmoid'))\n",
    "finetune_vgg16.summary()\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 6s 822ms/step - loss: 0.9892 - acc: 0.5223 - val_loss: 0.5689 - val_acc: 0.5893\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 4s 536ms/step - loss: 0.7542 - acc: 0.5759 - val_loss: 0.4904 - val_acc: 0.7679\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 4s 598ms/step - loss: 0.5040 - acc: 0.7500 - val_loss: 0.3728 - val_acc: 0.9286\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 4s 572ms/step - loss: 0.4611 - acc: 0.7589 - val_loss: 0.3229 - val_acc: 0.9286\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 4s 569ms/step - loss: 0.3601 - acc: 0.8750 - val_loss: 0.2652 - val_acc: 0.9286\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 4s 552ms/step - loss: 0.2957 - acc: 0.9196 - val_loss: 0.2089 - val_acc: 0.9643\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 4s 590ms/step - loss: 0.2739 - acc: 0.9018 - val_loss: 0.1912 - val_acc: 0.9821\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 4s 564ms/step - loss: 0.2204 - acc: 0.9598 - val_loss: 0.1633 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 3s 505ms/step - loss: 0.2039 - acc: 0.9598 - val_loss: 0.1662 - val_acc: 0.9643\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 4s 547ms/step - loss: 0.2128 - acc: 0.9420 - val_loss: 0.1392 - val_acc: 0.9821\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 4s 527ms/step - loss: 0.1942 - acc: 0.9509 - val_loss: 0.1365 - val_acc: 0.9821\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 4s 549ms/step - loss: 0.1681 - acc: 0.9687 - val_loss: 0.1115 - val_acc: 1.0000\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 4s 566ms/step - loss: 0.1535 - acc: 0.9777 - val_loss: 0.1070 - val_acc: 0.9821\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 4s 550ms/step - loss: 0.1462 - acc: 0.9464 - val_loss: 0.0999 - val_acc: 0.9821\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 4s 556ms/step - loss: 0.1461 - acc: 0.9687 - val_loss: 0.0989 - val_acc: 0.9821\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 3s 509ms/step - loss: 0.1365 - acc: 0.9598 - val_loss: 0.1007 - val_acc: 0.9821\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 4s 552ms/step - loss: 0.1305 - acc: 0.9777 - val_loss: 0.0867 - val_acc: 0.9821\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 4s 510ms/step - loss: 0.1210 - acc: 0.9732 - val_loss: 0.0886 - val_acc: 0.9821\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 4s 561ms/step - loss: 0.1027 - acc: 0.9821 - val_loss: 0.0778 - val_acc: 0.9821\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 4s 638ms/step - loss: 0.0975 - acc: 0.9821 - val_loss: 0.0760 - val_acc: 0.9821\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 4s 634ms/step - loss: 0.0977 - acc: 0.9777 - val_loss: 0.0789 - val_acc: 0.9821\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 5s 760ms/step - loss: 0.1074 - acc: 0.9687 - val_loss: 0.0694 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 4s 652ms/step - loss: 0.0824 - acc: 0.9866 - val_loss: 0.0695 - val_acc: 0.9821\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 4s 569ms/step - loss: 0.0796 - acc: 0.9911 - val_loss: 0.0643 - val_acc: 0.9821\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 3s 519ms/step - loss: 0.0738 - acc: 0.9911 - val_loss: 0.0676 - val_acc: 0.9821\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 4s 545ms/step - loss: 0.0825 - acc: 0.9866 - val_loss: 0.0646 - val_acc: 0.9821\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 4s 644ms/step - loss: 0.0787 - acc: 0.9866 - val_loss: 0.0616 - val_acc: 0.9821\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 5s 711ms/step - loss: 0.0672 - acc: 0.9911 - val_loss: 0.0603 - val_acc: 0.9821\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 5s 767ms/step - loss: 0.0575 - acc: 0.9911 - val_loss: 0.0572 - val_acc: 0.9821\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 5s 664ms/step - loss: 0.0689 - acc: 0.9866 - val_loss: 0.0594 - val_acc: 0.9821\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 6s 885ms/step - loss: 0.0562 - acc: 0.9955 - val_loss: 0.0533 - val_acc: 0.9821\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 5s 707ms/step - loss: 0.0435 - acc: 1.0000 - val_loss: 0.0565 - val_acc: 0.9821\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 5s 712ms/step - loss: 0.0535 - acc: 0.9911 - val_loss: 0.0504 - val_acc: 0.9821\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 4s 625ms/step - loss: 0.0523 - acc: 0.9866 - val_loss: 0.0546 - val_acc: 0.9821\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 4s 575ms/step - loss: 0.0544 - acc: 0.9866 - val_loss: 0.0522 - val_acc: 0.9821\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 4s 606ms/step - loss: 0.0602 - acc: 0.9955 - val_loss: 0.0545 - val_acc: 0.9821\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 4s 576ms/step - loss: 0.0423 - acc: 0.9955 - val_loss: 0.0514 - val_acc: 0.9821\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 4s 560ms/step - loss: 0.0378 - acc: 0.9955 - val_loss: 0.0509 - val_acc: 0.9821\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 4s 624ms/step - loss: 0.0354 - acc: 1.0000 - val_loss: 0.0493 - val_acc: 0.9821\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 4s 640ms/step - loss: 0.0546 - acc: 0.9866 - val_loss: 0.0491 - val_acc: 0.9821\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 6s 865ms/step - loss: 0.0401 - acc: 1.0000 - val_loss: 0.0488 - val_acc: 0.9821\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 5s 750ms/step - loss: 0.0393 - acc: 1.0000 - val_loss: 0.0454 - val_acc: 0.9821\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 4s 623ms/step - loss: 0.0360 - acc: 0.9955 - val_loss: 0.0446 - val_acc: 0.9821\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 5s 648ms/step - loss: 0.0314 - acc: 1.0000 - val_loss: 0.0478 - val_acc: 0.9821\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 4s 586ms/step - loss: 0.0239 - acc: 1.0000 - val_loss: 0.0486 - val_acc: 0.9821\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 4s 638ms/step - loss: 0.0284 - acc: 1.0000 - val_loss: 0.0452 - val_acc: 0.9821\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 4s 602ms/step - loss: 0.0347 - acc: 0.9955 - val_loss: 0.0476 - val_acc: 0.9821\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 5s 681ms/step - loss: 0.0290 - acc: 1.0000 - val_loss: 0.0440 - val_acc: 0.9821\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 4s 600ms/step - loss: 0.0224 - acc: 0.9955 - val_loss: 0.0439 - val_acc: 0.9821\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 4s 652ms/step - loss: 0.0304 - acc: 1.0000 - val_loss: 0.0432 - val_acc: 0.9821\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 4s 621ms/step - loss: 0.0247 - acc: 1.0000 - val_loss: 0.0422 - val_acc: 0.9821\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 4s 598ms/step - loss: 0.0202 - acc: 1.0000 - val_loss: 0.0425 - val_acc: 0.9821\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 4s 623ms/step - loss: 0.0236 - acc: 1.0000 - val_loss: 0.0406 - val_acc: 0.9821\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 4s 575ms/step - loss: 0.0228 - acc: 1.0000 - val_loss: 0.0409 - val_acc: 0.9821\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 4s 593ms/step - loss: 0.0289 - acc: 0.9955 - val_loss: 0.0404 - val_acc: 0.9821\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 4s 628ms/step - loss: 0.0182 - acc: 1.0000 - val_loss: 0.0390 - val_acc: 0.9821\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 4s 562ms/step - loss: 0.0228 - acc: 1.0000 - val_loss: 0.0399 - val_acc: 0.9821\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 4s 577ms/step - loss: 0.0203 - acc: 1.0000 - val_loss: 0.0407 - val_acc: 0.9821\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 4s 661ms/step - loss: 0.0211 - acc: 0.9955 - val_loss: 0.0383 - val_acc: 0.9821\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 4s 577ms/step - loss: 0.0177 - acc: 1.0000 - val_loss: 0.0403 - val_acc: 0.9821\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 4s 615ms/step - loss: 0.0193 - acc: 1.0000 - val_loss: 0.0382 - val_acc: 0.9821\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 4s 624ms/step - loss: 0.0231 - acc: 0.9911 - val_loss: 0.0383 - val_acc: 0.9821\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 4s 623ms/step - loss: 0.0184 - acc: 1.0000 - val_loss: 0.0423 - val_acc: 0.9821\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 4s 652ms/step - loss: 0.0160 - acc: 1.0000 - val_loss: 0.0411 - val_acc: 0.9821\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 4s 618ms/step - loss: 0.0174 - acc: 1.0000 - val_loss: 0.0384 - val_acc: 0.9821\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 5s 679ms/step - loss: 0.0199 - acc: 1.0000 - val_loss: 0.0474 - val_acc: 0.9821\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 5s 736ms/step - loss: 0.0156 - acc: 1.0000 - val_loss: 0.0380 - val_acc: 0.9821\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 4s 563ms/step - loss: 0.0162 - acc: 1.0000 - val_loss: 0.0388 - val_acc: 0.9821\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 4s 559ms/step - loss: 0.0198 - acc: 1.0000 - val_loss: 0.0477 - val_acc: 0.9821\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 5s 699ms/step - loss: 0.0150 - acc: 1.0000 - val_loss: 0.0367 - val_acc: 0.9821\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 4s 638ms/step - loss: 0.0133 - acc: 1.0000 - val_loss: 0.0377 - val_acc: 0.9821\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 4s 633ms/step - loss: 0.0119 - acc: 1.0000 - val_loss: 0.0364 - val_acc: 0.9821\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 4s 633ms/step - loss: 0.0186 - acc: 0.9955 - val_loss: 0.0404 - val_acc: 0.9821\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 4s 588ms/step - loss: 0.0154 - acc: 1.0000 - val_loss: 0.0370 - val_acc: 0.9821\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 4s 643ms/step - loss: 0.0143 - acc: 1.0000 - val_loss: 0.0385 - val_acc: 0.9821\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 4s 558ms/step - loss: 0.0132 - acc: 1.0000 - val_loss: 0.0396 - val_acc: 0.9821\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 4s 617ms/step - loss: 0.0150 - acc: 1.0000 - val_loss: 0.0350 - val_acc: 0.9821\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 4s 571ms/step - loss: 0.0182 - acc: 0.9955 - val_loss: 0.0389 - val_acc: 0.9821\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 4s 577ms/step - loss: 0.0114 - acc: 1.0000 - val_loss: 0.0372 - val_acc: 0.9821\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 4s 605ms/step - loss: 0.0135 - acc: 1.0000 - val_loss: 0.0338 - val_acc: 0.9821\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 4s 574ms/step - loss: 0.0142 - acc: 1.0000 - val_loss: 0.0342 - val_acc: 0.9821\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 4s 574ms/step - loss: 0.0140 - acc: 1.0000 - val_loss: 0.0369 - val_acc: 0.9821\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 4s 560ms/step - loss: 0.0104 - acc: 1.0000 - val_loss: 0.0348 - val_acc: 0.9821\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 4s 563ms/step - loss: 0.0100 - acc: 1.0000 - val_loss: 0.0361 - val_acc: 0.9821\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 4s 564ms/step - loss: 0.0157 - acc: 1.0000 - val_loss: 0.0382 - val_acc: 0.9821\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 4s 565ms/step - loss: 0.0141 - acc: 1.0000 - val_loss: 0.0345 - val_acc: 0.9821\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 4s 558ms/step - loss: 0.0120 - acc: 1.0000 - val_loss: 0.0340 - val_acc: 0.9821\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 4s 569ms/step - loss: 0.0124 - acc: 1.0000 - val_loss: 0.0373 - val_acc: 0.9821\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 4s 559ms/step - loss: 0.0127 - acc: 1.0000 - val_loss: 0.0359 - val_acc: 0.9821\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 4s 584ms/step - loss: 0.0141 - acc: 0.9955 - val_loss: 0.0330 - val_acc: 0.9821\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 4s 557ms/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.0347 - val_acc: 0.9821\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 4s 561ms/step - loss: 0.0223 - acc: 0.9911 - val_loss: 0.0343 - val_acc: 0.9821\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 4s 575ms/step - loss: 0.0120 - acc: 1.0000 - val_loss: 0.0348 - val_acc: 0.9821\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 4s 579ms/step - loss: 0.0104 - acc: 1.0000 - val_loss: 0.0345 - val_acc: 0.9821\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 4s 573ms/step - loss: 0.0125 - acc: 1.0000 - val_loss: 0.0367 - val_acc: 0.9821\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 4s 556ms/step - loss: 0.0134 - acc: 1.0000 - val_loss: 0.0351 - val_acc: 0.9821\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 4s 563ms/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.0380 - val_acc: 0.9821\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 4s 554ms/step - loss: 0.0148 - acc: 0.9955 - val_loss: 0.0331 - val_acc: 0.9821\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 4s 623ms/step - loss: 0.0118 - acc: 1.0000 - val_loss: 0.0329 - val_acc: 0.9821\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 4s 563ms/step - loss: 0.0085 - acc: 1.0000 - val_loss: 0.0376 - val_acc: 0.9821\n"
     ]
    }
   ],
   "source": [
    "finetune_vgg16.compile(loss='binary_crossentropy',optimizer='adam',metrics='acc')\n",
    "checkpoint=keras.callbacks.ModelCheckpoint(filepath='./new.h5',\n",
    "                                           save_best_only=True)\n",
    "early_stopping=keras.callbacks.EarlyStopping(patience=10)\n",
    "with tf.device('/GPU:0'):\n",
    "    history=finetune_vgg16.fit(X_train,y_train,epochs=100,batch_size=32,\n",
    "                      validation_data=(X_val,y_val),\n",
    "                      callbacks=[checkpoint,early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 342ms/step - loss: 0.0376 - acc: 0.9821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.037592239677906036, 0.9821428060531616]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetune_vgg16.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 74, 74, 32)   864         ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 74, 74, 32)  96          ['conv2d_2[0][0]']               \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 74, 74, 32)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 72, 72, 32)   9216        ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 72, 72, 32)  96          ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 72, 72, 32)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 72, 72, 64)   18432       ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 72, 72, 64)  192         ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 72, 72, 64)   0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 64)  0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 35, 35, 80)   5120        ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 35, 35, 80)  240         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 35, 35, 80)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 33, 33, 192)  138240      ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 33, 33, 192)  576        ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 33, 33, 192)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 192)  0          ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 16, 16, 64)   12288       ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_10[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 16, 16, 48)   9216        ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 16, 16, 48)  144         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 16, 16, 96)  288         ['conv2d_11[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 16, 16, 48)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 16, 16, 96)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 16, 16, 192)  0          ['max_pooling2d_2[0][0]']        \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 16, 16, 64)   12288       ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 16, 16, 64)   76800       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 16, 16, 32)   6144        ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 16, 16, 96)  288         ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 16, 16, 32)  96          ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 16, 16, 32)   0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)           (None, 16, 16, 256)  0           ['activation_5[0][0]',           \n",
      "                                                                  'activation_7[0][0]',           \n",
      "                                                                  'activation_10[0][0]',          \n",
      "                                                                  'activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 16, 16, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 16, 16, 64)  192         ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 16, 16, 48)   12288       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 16, 16, 48)  144         ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 16, 16, 96)  288         ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 16, 16, 48)   0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 16, 16, 256)  0          ['mixed0[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 16, 16, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 16, 16, 64)   76800       ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 16, 16, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 16, 16, 64)  192         ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 16, 16, 64)  192         ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 16, 16, 96)  288         ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 16, 16, 64)  192         ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)           (None, 16, 16, 288)  0           ['activation_12[0][0]',          \n",
      "                                                                  'activation_14[0][0]',          \n",
      "                                                                  'activation_17[0][0]',          \n",
      "                                                                  'activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 16, 16, 64)  192         ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 16, 16, 48)   13824       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 16, 16, 48)  144         ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 16, 16, 96)  288         ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 16, 16, 48)   0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_2 (AveragePo  (None, 16, 16, 288)  0          ['mixed1[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 16, 16, 64)   76800       ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 16, 16, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 16, 16, 64)  192         ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 16, 16, 64)  192         ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 16, 16, 96)  288         ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 16, 16, 64)  192         ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)           (None, 16, 16, 288)  0           ['activation_19[0][0]',          \n",
      "                                                                  'activation_21[0][0]',          \n",
      "                                                                  'activation_24[0][0]',          \n",
      "                                                                  'activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 16, 16, 64)  192         ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 16, 16, 96)  288         ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 7, 7, 384)    995328      ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 7, 7, 96)     82944       ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 7, 7, 384)   1152        ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 7, 7, 96)    288         ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 7, 7, 384)    0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 7, 7, 96)     0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 7, 7, 288)   0           ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)           (None, 7, 7, 768)    0           ['activation_26[0][0]',          \n",
      "                                                                  'activation_29[0][0]',          \n",
      "                                                                  'max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 7, 7, 128)    98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 7, 7, 128)   384         ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 7, 7, 128)   384         ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 7, 7, 128)    98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 7, 7, 128)   384         ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 7, 7, 128)   384         ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 7, 7, 128)   384         ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 7, 7, 128)   384         ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_3 (AveragePo  (None, 7, 7, 768)   0           ['mixed3[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 7, 7, 192)    172032      ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 7, 7, 192)    172032      ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_3[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 7, 7, 192)   576         ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 7, 7, 192)   576         ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 7, 7, 192)   576         ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 7, 7, 192)   576         ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)           (None, 7, 7, 768)    0           ['activation_30[0][0]',          \n",
      "                                                                  'activation_33[0][0]',          \n",
      "                                                                  'activation_38[0][0]',          \n",
      "                                                                  'activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 7, 7, 160)   480         ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 7, 7, 160)   480         ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 7, 7, 160)   480         ['conv2d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 7, 7, 160)   480         ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 7, 7, 160)   480         ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 7, 7, 160)   480         ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_4 (AveragePo  (None, 7, 7, 768)   0           ['mixed4[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_4[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 7, 7, 192)   576         ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 7, 7, 192)   576         ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 7, 7, 192)   576         ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 7, 7, 192)   576         ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)           (None, 7, 7, 768)    0           ['activation_40[0][0]',          \n",
      "                                                                  'activation_43[0][0]',          \n",
      "                                                                  'activation_48[0][0]',          \n",
      "                                                                  'activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 7, 7, 160)   480         ['conv2d_56[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_54[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 7, 7, 160)   480         ['conv2d_57[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_55 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_55[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 7, 7, 160)   480         ['conv2d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 7, 7, 160)   480         ['conv2d_58[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " activation_56 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_56[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 7, 7, 160)   480         ['conv2d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 7, 7, 160)   480         ['conv2d_59[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " activation_57 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_5 (AveragePo  (None, 7, 7, 768)   0           ['mixed5[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_52[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_57[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_5[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 7, 7, 192)   576         ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 7, 7, 192)   576         ['conv2d_55[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 7, 7, 192)   576         ['conv2d_60[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, 7, 7, 192)   576         ['conv2d_61[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " activation_58 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " activation_59 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)           (None, 7, 7, 768)    0           ['activation_50[0][0]',          \n",
      "                                                                  'activation_53[0][0]',          \n",
      "                                                                  'activation_58[0][0]',          \n",
      "                                                                  'activation_59[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_64 (BatchN  (None, 7, 7, 192)   576         ['conv2d_66[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_64 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_64[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_64[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_65 (BatchN  (None, 7, 7, 192)   576         ['conv2d_67[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_65 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_65[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_65[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_61 (BatchN  (None, 7, 7, 192)   576         ['conv2d_63[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_66 (BatchN  (None, 7, 7, 192)   576         ['conv2d_68[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_61 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " activation_66 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_66[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_61[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_66[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_62 (BatchN  (None, 7, 7, 192)   576         ['conv2d_64[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_67 (BatchN  (None, 7, 7, 192)   576         ['conv2d_69[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_62 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " activation_67 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_67[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_6 (AveragePo  (None, 7, 7, 768)   0           ['mixed6[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_62[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_67[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_6[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_60 (BatchN  (None, 7, 7, 192)   576         ['conv2d_62[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_63 (BatchN  (None, 7, 7, 192)   576         ['conv2d_65[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_68 (BatchN  (None, 7, 7, 192)   576         ['conv2d_70[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_69 (BatchN  (None, 7, 7, 192)   576         ['conv2d_71[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_60 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " activation_63 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " activation_68 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " activation_69 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)           (None, 7, 7, 768)    0           ['activation_60[0][0]',          \n",
      "                                                                  'activation_63[0][0]',          \n",
      "                                                                  'activation_68[0][0]',          \n",
      "                                                                  'activation_69[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, 7, 7, 192)   576         ['conv2d_74[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_72 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_72[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, 7, 7, 192)   576         ['conv2d_75[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_73 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_73[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_70 (BatchN  (None, 7, 7, 192)   576         ['conv2d_72[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, 7, 7, 192)   576         ['conv2d_76[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_70 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " activation_74 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)             (None, 3, 3, 320)    552960      ['activation_70[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)             (None, 3, 3, 192)    331776      ['activation_74[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_71 (BatchN  (None, 3, 3, 320)   960         ['conv2d_73[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, 3, 3, 192)   576         ['conv2d_77[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_71 (Activation)     (None, 3, 3, 320)    0           ['batch_normalization_71[0][0]'] \n",
      "                                                                                                  \n",
      " activation_75 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_75[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 3, 3, 768)   0           ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed8 (Concatenate)           (None, 3, 3, 1280)   0           ['activation_71[0][0]',          \n",
      "                                                                  'activation_75[0][0]',          \n",
      "                                                                  'max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)             (None, 3, 3, 448)    573440      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_80 (BatchN  (None, 3, 3, 448)   1344        ['conv2d_82[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_80 (Activation)     (None, 3, 3, 448)    0           ['batch_normalization_80[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)             (None, 3, 3, 384)    491520      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)             (None, 3, 3, 384)    1548288     ['activation_80[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_79[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_81 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_83[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_77 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " activation_81 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_81[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_7 (AveragePo  (None, 3, 3, 1280)  0           ['mixed8[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)             (None, 3, 3, 320)    409600      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_78 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_80[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_79 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_81[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_82 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_84[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_83 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_85[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)             (None, 3, 3, 192)    245760      ['average_pooling2d_7[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, 3, 3, 320)   960         ['conv2d_78[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_78 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_78[0][0]'] \n",
      "                                                                                                  \n",
      " activation_79 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_79[0][0]'] \n",
      "                                                                                                  \n",
      " activation_82 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_82[0][0]'] \n",
      "                                                                                                  \n",
      " activation_83 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_83[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_84 (BatchN  (None, 3, 3, 192)   576         ['conv2d_86[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_76 (Activation)     (None, 3, 3, 320)    0           ['batch_normalization_76[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_0 (Concatenate)         (None, 3, 3, 768)    0           ['activation_78[0][0]',          \n",
      "                                                                  'activation_79[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 3, 3, 768)    0           ['activation_82[0][0]',          \n",
      "                                                                  'activation_83[0][0]']          \n",
      "                                                                                                  \n",
      " activation_84 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_84[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9 (Concatenate)           (None, 3, 3, 2048)   0           ['activation_76[0][0]',          \n",
      "                                                                  'mixed9_0[0][0]',               \n",
      "                                                                  'concatenate[0][0]',            \n",
      "                                                                  'activation_84[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)             (None, 3, 3, 448)    917504      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_89 (BatchN  (None, 3, 3, 448)   1344        ['conv2d_91[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_89 (Activation)     (None, 3, 3, 448)    0           ['batch_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)             (None, 3, 3, 384)    786432      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)             (None, 3, 3, 384)    1548288     ['activation_89[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_86 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_88[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_90 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_92[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_86 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_86[0][0]'] \n",
      "                                                                                                  \n",
      " activation_90 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_90[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_93 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_94 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_8 (AveragePo  (None, 3, 3, 2048)  0           ['mixed9[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)             (None, 3, 3, 320)    655360      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_87 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_89[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_88 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_90[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_91 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_93[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_92 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_94[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_95 (Conv2D)             (None, 3, 3, 192)    393216      ['average_pooling2d_8[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_85 (BatchN  (None, 3, 3, 320)   960         ['conv2d_87[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_87 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_87[0][0]'] \n",
      "                                                                                                  \n",
      " activation_88 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_88[0][0]'] \n",
      "                                                                                                  \n",
      " activation_91 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " activation_92 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_92[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_93 (BatchN  (None, 3, 3, 192)   576         ['conv2d_95[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_85 (Activation)     (None, 3, 3, 320)    0           ['batch_normalization_85[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_1 (Concatenate)         (None, 3, 3, 768)    0           ['activation_87[0][0]',          \n",
      "                                                                  'activation_88[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 3, 3, 768)    0           ['activation_91[0][0]',          \n",
      "                                                                  'activation_92[0][0]']          \n",
      "                                                                                                  \n",
      " activation_93 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_93[0][0]'] \n",
      "                                                                                                  \n",
      " mixed10 (Concatenate)          (None, 3, 3, 2048)   0           ['activation_85[0][0]',          \n",
      "                                                                  'mixed9_1[0][0]',               \n",
      "                                                                  'concatenate_1[0][0]',          \n",
      "                                                                  'activation_93[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 0\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inception_v3 (Functional)   (None, 3, 3, 2048)        21802784  \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 18432)             0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                1179712   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,982,561\n",
      "Trainable params: 1,179,777\n",
      "Non-trainable params: 21,802,784\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 9s 326ms/step - loss: 3.4447 - acc: 0.6786 - val_loss: 0.7156 - val_acc: 0.8929\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 3s 237ms/step - loss: 0.9413 - acc: 0.8839 - val_loss: 0.0992 - val_acc: 0.9821\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 2s 151ms/step - loss: 0.3429 - acc: 0.9509 - val_loss: 0.1022 - val_acc: 0.9464\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 2s 137ms/step - loss: 0.1809 - acc: 0.9598 - val_loss: 0.1151 - val_acc: 0.9821\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 4s 293ms/step - loss: 0.1250 - acc: 0.9643 - val_loss: 0.0606 - val_acc: 0.9821\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 2s 136ms/step - loss: 0.0419 - acc: 0.9821 - val_loss: 0.0744 - val_acc: 0.9821\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 3s 192ms/step - loss: 0.0312 - acc: 0.9911 - val_loss: 0.0554 - val_acc: 0.9821\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 2s 156ms/step - loss: 0.0242 - acc: 0.9911 - val_loss: 0.0728 - val_acc: 0.9821\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 2s 145ms/step - loss: 0.0358 - acc: 0.9866 - val_loss: 0.0842 - val_acc: 0.9464\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 2s 145ms/step - loss: 0.0296 - acc: 0.9911 - val_loss: 0.1063 - val_acc: 0.9821\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 2s 136ms/step - loss: 0.0238 - acc: 0.9955 - val_loss: 0.0995 - val_acc: 0.9821\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 3s 191ms/step - loss: 0.0197 - acc: 0.9911 - val_loss: 0.0358 - val_acc: 0.9821\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 2s 137ms/step - loss: 0.0143 - acc: 0.9911 - val_loss: 0.0739 - val_acc: 0.9821\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 2s 135ms/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.0568 - val_acc: 0.9821\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 2s 136ms/step - loss: 0.0136 - acc: 0.9911 - val_loss: 0.0930 - val_acc: 0.9821\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 2s 132ms/step - loss: 0.0112 - acc: 0.9955 - val_loss: 0.0614 - val_acc: 0.9821\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 2s 136ms/step - loss: 0.0076 - acc: 0.9955 - val_loss: 0.0851 - val_acc: 0.9821\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 2s 135ms/step - loss: 0.0069 - acc: 0.9955 - val_loss: 0.0985 - val_acc: 0.9821\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 2s 132ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.1063 - val_acc: 0.9821\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 2s 131ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0573 - val_acc: 0.9821\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 2s 135ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0837 - val_acc: 0.9821\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 2s 134ms/step - loss: 0.0137 - acc: 0.9911 - val_loss: 0.1021 - val_acc: 0.9821\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "model = InceptionV3(weights='imagenet', include_top=False,input_shape=(150,150,3))\n",
    "\n",
    "model.trainable=False\n",
    "model.summary()\n",
    "finetune_V3=keras.Sequential()\n",
    "finetune_V3.add(model)\n",
    "finetune_V3.add(keras.layers.Flatten())\n",
    "finetune_V3.add(keras.layers.Dense(64,activation='relu'))\n",
    "finetune_V3.add(keras.layers.Dropout(0.3))\n",
    "finetune_V3.add(keras.layers.Dense(1,activation='sigmoid'))\n",
    "finetune_V3.summary()\n",
    "finetune_V3.compile(loss='binary_crossentropy',optimizer='adam',metrics='acc')\n",
    "checkpoint=keras.callbacks.ModelCheckpoint(filepath='./newV3.h5',\n",
    "                                           save_best_only=True)\n",
    "early_stopping=keras.callbacks.EarlyStopping(patience=10)\n",
    "with tf.device('/GPU:0'):\n",
    "    history=finetune_V3.fit(X_train,y_train,epochs=100,batch_size=16,\n",
    "                        validation_data=(X_val,y_val),\n",
    "                        callbacks=[checkpoint,early_stopping])                   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 143ms/step - loss: 0.1021 - acc: 0.9821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10209713876247406, 0.9821428060531616]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetune_V3.evaluate(X_val, y_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
